#!/usr/bin/env python3
# this script generated by chatGPT as a response to the question of 
# how to batch process prompts for the A.I. natural language proc.

import openai

def generate_response(prompt, temperature=0.7):
    response = openai.Completion.create(
        engine="text-davinci-002",
        prompt=prompt,
        max_tokens=1024,
        n=1,
        stop=None,
        temperature=temperature
    ).choices[0].text
    return response

def main(filename):
    with open(filename, "r") as f:
        prompts = f.readlines()
    output = []
    for prompt in prompts:
        response = generate_response(prompt, temperature=0.7)
        output.append("Prompt: " + prompt + "\nResponse: " + response + "\n")
    with open("output.txt", "w") as f:
        f.write("\n".join(output))

if __name__ == "__main__":
    import sys
    filename = sys.argv[1]
    main(filename)
