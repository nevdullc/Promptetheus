# Promptetheus

This script is a work in progress, not quite working yet, the exexution is ok, but there are limitations to the 
current methods employed: 

openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.

Python scripting to process a list of prompts for openAI to process in a batch, providing output to a local file.
chatGPT prompt:please help write a python script that takes a list of prompts as it's 
input argument, (a file name on the command line), the script should iterate 
through each prompt individually passing it through the Davinci Language model 
with a temperature of 0.7, answering each prompt in turn and appending the 
prompt and the open A.I. response in an orderly format in an output file located 
in the . local file 

Here's a script that takes a list of prompts from a file, passes each prompt 
through the OpenAI GPT-3 model with a temperature of 0.7, and appends the prompt 
and response in an output file:

python
<code>
import openai

def generate_response(prompt, temperature=0.7):
    response = openai.Completion.create(
        engine="text-davinci-002",
        prompt=prompt,
        max_tokens=1024,
        n=1,
        stop=None,
        temperature=temperature
    ).choices[0].text
    return response

def main(filename):
    with open(filename, "r") as f:
        prompts = f.readlines()
    output = []
    for prompt in prompts:
        response = generate_response(prompt, temperature=0.7)
        output.append("Prompt: " + prompt + "\nResponse: " + response + "\n")
    with open("output.txt", "w") as f:
        f.write("\n".join(output))

if __name__ == "__main__":
    import sys
    filename = sys.argv[1]
    main(filename)
    
</code>

This script uses the openai module to access the GPT-3 API, which is the OpenAI 
API that provides access to the GPT-3 language model. The generate_response 
function takes a prompt and a temperature as arguments and returns the response 
generated by the API. The main function reads the list of prompts from the file, 
generates responses for each prompt using the generate_response function, and 
writes the prompt-response pairs in the format 
"Prompt: [prompt]\nResponse:[response]\n" to an output file named output.txt.

<<EOF
So.. this is the starting point for the batch prompt script, I've already asked
  the chatGPT to create lists of questions about life, the universe and everything.
  This script will answer those questions .. simply as a python learning excercise.
  ::nevdullc
